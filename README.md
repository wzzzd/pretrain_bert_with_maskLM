# Pretrain_Bert_with_MaskLM
ä½¿ç”¨Mask LMé¢„è®­ç»ƒä»»åŠ¡æ¥é¢„è®­ç»ƒBertæ¨¡å‹ã€‚

è®­ç»ƒå…³äºå‚ç›´é¢†åŸŸè¯­æ–™çš„æ¨¡å‹è¡¨å¾ï¼Œæå‡ä¸‹æ¸¸ä»»åŠ¡çš„è¡¨ç°ã€‚

åŸºäºpytorchã€‚


## Pretraining Task
Mask Language Modelï¼Œç®€ç§°Mask LMï¼Œå³åŸºäºMaskæœºåˆ¶çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚
ä½¿ç”¨æ¥è‡ªäºBertçš„maskæœºåˆ¶ï¼Œå³å¯¹äºæ¯ä¸€ä¸ªå¥å­ä¸­çš„è¯ï¼ˆtokenï¼‰ï¼š
* 85%çš„æ¦‚ç‡ï¼Œä¿ç•™åŸè¯ä¸å˜
* 15%çš„æ¦‚ç‡ï¼Œä½¿ç”¨ä»¥ä¸‹æ–¹å¼æ›¿æ¢
    * 80%çš„æ¦‚ç‡ï¼Œä½¿ç”¨å­—ç¬¦'[MASK]'ï¼Œæ›¿æ¢å½“å‰tokenã€‚
    * 10%çš„æ¦‚ç‡ï¼Œä½¿ç”¨è¯è¡¨éšæœºæŠ½å–çš„tokenï¼Œæ›¿æ¢å½“å‰tokenã€‚
    * 10%çš„æ¦‚ç‡ï¼Œä¿ç•™åŸè¯ä¸å˜ã€‚
* paper
    <!-- * ![](./picture/mask_method.png) -->
    * <img src=./picture/mask_method.png width=50% />

## Model
ä½¿ç”¨åŸç”Ÿçš„Bertæ¨¡å‹ä½œä¸ºåŸºå‡†æ¨¡å‹ã€‚
* ![](./picture/bert_architecture.png)


## Datasets
é¡¹ç›®é‡Œçš„æ•°æ®é›†æ¥è‡ªwikitextï¼Œåˆ†æˆä¸¤ä¸ªæ–‡ä»¶è®­ç»ƒé›†ï¼ˆtrain.txtï¼‰å’Œæµ‹è¯•é›†ï¼ˆtest.txtï¼‰ã€‚

æ•°æ®ä»¥è¡Œä¸ºå•ä½å­˜å‚¨ã€‚

è‹¥æƒ³è¦æ›¿æ¢æˆè‡ªå·±çš„æ•°æ®é›†ï¼Œå¯ä»¥ä½¿ç”¨è‡ªå·±çš„æ•°æ®é›†è¿›è¡Œæ›¿æ¢ã€‚ï¼ˆæ³¨æ„ï¼šå¦‚æœæ˜¯é¢„è®­ç»ƒä¸­æ–‡æ¨¡å‹ï¼Œéœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶Config.pyä¸­çš„self.initial_pretrain_modelå’Œself.initial_pretrain_tokenizerï¼Œå°†å€¼ä¿®æ”¹æˆ bert-base-chineseï¼‰

è‡ªå·±çš„æ•°æ®é›†ä¸éœ€è¦åšmaskæœºåˆ¶å¤„ç†ï¼Œä»£ç ä¼šå¤„ç†ã€‚


## Training Target
æœ¬é¡¹ç›®ç›®çš„åœ¨äºåŸºäºç°æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹å‚æ•°ï¼Œå¦‚googleå¼€æºçš„bert-base-uncasedã€bert-base-chineseç­‰ï¼Œåœ¨å‚ç›´é¢†åŸŸçš„æ•°æ®è¯­æ–™ä¸Šï¼Œå†æ¬¡è¿›è¡Œé¢„è®­ç»ƒä»»åŠ¡ï¼Œç”±æ­¤æå‡bertçš„æ¨¡å‹è¡¨å¾èƒ½åŠ›ï¼Œæ¢å¥è¯è¯´ï¼Œä¹Ÿå°±æ˜¯æå‡ä¸‹æ¸¸ä»»åŠ¡çš„è¡¨ç°ã€‚


## Environment

é¡¹ç›®ä¸»è¦ä½¿ç”¨äº†Huggingfaceçš„datasetsã€transformersã€accelerateæ¨¡å—ï¼Œæ”¯æŒå•å¡å•æœºã€å•æœºå¤šå¡ä¸¤ç§æ¨¡å¼ã€‚æ”¯æŒä½¿ç”¨FP16ç²¾åº¦åŠ é€Ÿè®­ç»ƒã€‚


å¯é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–åŒ…
```
    pip install -r requirement.txt
```
ä¸»è¦åŒ…å«çš„æ¨¡å—å¦‚ä¸‹ï¼š
```
    python3.6
    torch==1.9.0
    tqdm==4.61.2
    transformers==4.9.1
    datasets==1.10.2
    accelerate==0.3.0
    numpy==1.19.5
    pandas==1.1.5
```



## Get Start

### å•å¡æ¨¡å¼
ç›´æ¥è¿è¡Œä»¥ä¸‹å‘½ä»¤
```
    python train.py
```
æˆ–ä¿®æ”¹Config.pyæ–‡ä»¶ä¸­çš„å˜é‡self.cuda_visible_devicesä¸ºå•å¡åï¼Œè¿è¡Œ
```
    chmod 755 run.sh
    ./run.sh
```

### å¤šå¡æ¨¡å¼
å¦‚æœä½ ä¸é‚£ä¹ˆå¹¸è¿ï¼Œæ‹¥æœ‰äº†å¤šå¼ GPUå¡ï¼Œé‚£ä¹ˆæ­å–œä½ ï¼Œä½ å¯ä»¥è¿›å…¥èµ·é£æ¨¡å¼ã€‚ğŸš€ğŸš€

ï¼ˆ1ï¼‰é€šè¿‡ä¿®æ”¹Config.pyæ–‡ä»¶ä¸­çš„å˜é‡self.cuda_visible_devicesï¼ŒæŒ‡å®šä½ éœ€è¦åœ¨å“ªå‡ å¼ å¡ä¸Šè¿è¡Œï¼Œå¡å·ä¹‹é—´ä»¥è‹±æ–‡é€—å·éš”å¼€ã€‚
ï¼ˆ2ï¼‰å› ä¸ºä½¿ç”¨çš„æ˜¯accelerateåŠ é€Ÿæ¨¡å—ï¼Œæ•…éœ€è¦é…ç½®ä¸€äº›ç¯å¢ƒä¿¡æ¯ï¼Œåœ¨ç¡®ä¿å®‰è£…å®Œç¯å¢ƒæ‰€ä»¥çš„ä¾èµ–åŒ…åï¼Œè¿è¡Œå‘½ä»¤ï¼š
```
    accelerate config
```
ï¼ˆ3ï¼‰åé¢åœ¨ç»ˆç«¯ä¼šå¼¹å‡ºä»¥ä¸‹é—®é¢˜è®©ä½ å›ç­”ï¼Œéœ€è¦å›å¤å¯¹åº”çš„æ•°å­—æ¥é…ç½®ä¿¡æ¯ï¼Œä»¥ä¸‹æ˜¯ç¤ºä¾‹ï¼š
* In which compute environment are you running? ([0] This machine, [1] AWS (Amazon SageMaker)):
    * å›å¤0+å›è½¦ï¼šåœ¨æœ¬æœºè¿è¡Œ
* Which type of machine are you using? ([0] No distributed training, [1] multi-GPU, [2] TPU):
    * å›å¤1+å›è½¦ï¼šä½¿ç”¨å¤šå¡è®­ç»ƒæ¨¡å¼
* How many different machines will you use (use more than 1 for multi-node training)? [1]: 
    * å›å¤1+å›è½¦ï¼šä½¿ç”¨å¤šäºä¸€å¼ å¡
* How many processes in total will you use? [1]: 
    * å›å¤1+å›è½¦ï¼šå¯åŠ¨ä¸¤ä¸ªè¿›ç¨‹è¿è¡Œ
* Do you wish to use FP16 (mixed precision)? [yes/NO]:
    * å›å¤NO+å›è½¦ï¼šä¸ä½¿ç”¨FP16å•ç²¾åº¦åŠ é€Ÿ
* ![](./picture/accelerate_config.png)

ï¼ˆ4ï¼‰è¿è¡Œç¨‹åºå¯åŠ¨å‘½ä»¤
```
    chmod 755 run.sh
    ./run.sh
```

# Experiment
ä½¿ç”¨äº¤å‰ç†µï¼ˆcross-entropyï¼‰ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œå›°æƒ‘åº¦ï¼ˆperplexityï¼‰å’ŒLossä½œä¸ºè¯„ä»·æŒ‡æ ‡æ¥è¿›è¡Œè®­ç»ƒï¼Œè®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹ï¼š
<!-- ![](./picture/experiment.png) -->
<img src=./picture/experiment.png width=70% />




# Reference

ã€Bertã€‘[https://arxiv.org/pdf/1810.04805.pdf](https://arxiv.org/pdf/1810.04805.pdf)

ã€transformersã€‘[https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)

ã€datasetsã€‘[https://huggingface.co/docs/datasets/quicktour.html](https://huggingface.co/docs/datasets/quicktour.html)

ã€accelerateã€‘[https://huggingface.co/docs/accelerate/quicktour.html](https://huggingface.co/docs/accelerate/quicktour.html)


